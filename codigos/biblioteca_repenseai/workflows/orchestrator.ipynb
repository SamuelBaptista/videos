{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repenseai.genai.agent import Agent\n",
    "from repenseai.genai.tasks.api import Task\n",
    "from repenseai.genai.tasks.parallel import ParallelTask\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, List\n",
    "\n",
    "# Define Pydantic models for structured outputs\n",
    "class TaskDefinition(BaseModel):\n",
    "    original_task: str\n",
    "    task_type: Literal[\"formal\", \"conversational\", \"hybrid\"]\n",
    "    task_description: str\n",
    "\n",
    "class TaskList(BaseModel):\n",
    "    analysis: str\n",
    "    tasks: List[TaskDefinition] = Field(..., default_factory=list)\n",
    "\n",
    "# Define the prompts\n",
    "ORCHESTRATOR_PROMPT = \"\"\"\n",
    "Analyze this task and break it down into 2-3 distinct approaches:\n",
    "\n",
    "Task: {task}\n",
    "\n",
    "Provide an Analysis:\n",
    "\n",
    "Explain your understanding of the task and which variations would be valuable.\n",
    "Focus on how each approach serves different aspects of the task.\n",
    "\n",
    "Along with the analysis, provide 2-3 approaches to tackle the task, each with a brief description:\n",
    "\n",
    "Formal style: Write technically and precisely, focusing on detailed specifications\n",
    "Conversational style: Write in a friendly and engaging way that connects with the reader\n",
    "Hybrid style: Tell a story that includes technical details, combining emotional elements with specifications\n",
    "\n",
    "Return only JSON output.\n",
    "\"\"\"\n",
    "\n",
    "WORKER_PROMPT = \"\"\"\n",
    "Generate content based on:\n",
    "Task: {original_task}\n",
    "Style: {task_type}\n",
    "Guidelines: {task_description}\n",
    "\n",
    "Return only your response:\n",
    "[Your content here, maintaining the specified style and fully addressing requirements.]\n",
    "\"\"\"\n",
    "\n",
    "# Define the main task\n",
    "task = \"\"\"Write a product description for a new eco-friendly water bottle. \n",
    "The target audience is environmentally conscious millennials and key product features are: \n",
    "    1. plastic-free\n",
    "    2. insulated \n",
    "    3. lifetime warranty\n",
    "\"\"\"\n",
    "\n",
    "# Set up the orchestrator agent\n",
    "orchestrator_agent = Agent(\n",
    "    model=\"gpt-4o\",\n",
    "    model_type=\"chat\",\n",
    "    json_schema=TaskList,\n",
    ")\n",
    "\n",
    "# Create the orchestrator task\n",
    "orchestrator_task = Task(\n",
    "    user=ORCHESTRATOR_PROMPT,\n",
    "    agent=orchestrator_agent,\n",
    "    simple_response=True,\n",
    ")\n",
    "\n",
    "initial_results = orchestrator_task.run({'task': task})\n",
    "\n",
    "\n",
    "# Print orchestrator analysis and tasks\n",
    "print(\"\\n=== ORCHESTRATOR OUTPUT ===\")\n",
    "print(f\"\\nANALYSIS:\\n{initial_results['analysis']}\")\n",
    "print(f\"\\nTASKS:\")\n",
    "for task_info in initial_results['tasks']:\n",
    "    print(f\"Type: {task_info['task_type']}\")\n",
    "    print(f\"Description: {task_info['task_description']}\\n\")\n",
    "\n",
    "\n",
    "# Create worker tasks based on orchestrator output\n",
    "worker_agent = Agent(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    model_type=\"chat\",\n",
    ")\n",
    "\n",
    "output_tasks = initial_results['tasks']\n",
    "\n",
    "worker_task = Task(\n",
    "    user=WORKER_PROMPT, \n",
    "    agent=worker_agent, \n",
    "    simple_response=True\n",
    ") \n",
    "\n",
    "# Create a parallel task for all worker tasks\n",
    "parallel_worker_task = ParallelTask(tasks=worker_task)\n",
    "worker_results = parallel_worker_task.run(output_tasks)\n",
    "\n",
    "# Print worker results\n",
    "for task_info, response in zip(initial_results['tasks'], worker_results):\n",
    "    print(f\"\\n=== WORKER RESULT ({task_info['task_type']}) ===\\n{response}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
