{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.arionkoder.com/blog/building-an-ai-powered-eligibility-system-for-us-healthcare-part-i\n",
    "# https://www.arionkoder.com/blog/building-an-ai-powered-eligibility-system-for-us-healthcare-part-ii\n",
    "\n",
    "# https://www.anthropic.com/engineering/building-effective-agents\n",
    "# https://www.agentrecipes.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repenseai.genai.agent import Agent\n",
    "from repenseai.genai.tasks.api import Task\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    model=\"claude-3-7-sonnet-20250219\", # \"claude-3-5-sonnet-20241022\"\n",
    "    model_type=\"chat\",\n",
    ")\n",
    "\n",
    "task = Task(\n",
    "    user=\"What is the capital of france?\",\n",
    "    agent=agent,\n",
    "    simple_response=True\n",
    ")\n",
    "\n",
    "response = task.run()\n",
    "\n",
    "print()\n",
    "print(response.replace(\". \", \".\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python codigos/fundamentos_ai/characters.py 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Call - Output Estruturado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repenseai.genai.agent import Agent\n",
    "from repenseai.genai.tasks.api import Task\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    children: int\n",
    "\n",
    "\n",
    "sample1 = \"\"\"\n",
    "My name is Samuel, I'm 36 years old and I have a 3-month-old daughter and I want to have 3 more kids.\n",
    "\"\"\"\n",
    "\n",
    "sample2 = \"\"\"\n",
    "You are talking to Karen. She is a 30-year-old woman who has been a teacher for the past 12 years.\n",
    "She has two children, who are 12 and 15 years old.\n",
    "\"\"\"\n",
    "\n",
    "agent = Agent(\n",
    "    model=\"gpt-4o\",\n",
    "    model_type=\"chat\",\n",
    "    json_schema=User,\n",
    ")\n",
    "\n",
    "task = Task(\n",
    "    user=\"Extract the data from the text: \\n\\n {user}\",\n",
    "    agent=agent,\n",
    "    simple_response=True\n",
    ")\n",
    "\n",
    "response = task.run({\"user\": sample2})\n",
    "\n",
    "print()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repenseai.genai.agent import Agent\n",
    "from repenseai.genai.tasks.api import Task\n",
    "from repenseai.genai.tasks.workflow import Workflow\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "def check_children(context: dict):\n",
    "    children = context[\"user_output\"][\"children\"]\n",
    "    return children > 0\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    children: int\n",
    "\n",
    "\n",
    "sample1 = \"\"\"\n",
    "My name is Samuel, I'm 36 years and I dont have kids.\n",
    "\"\"\"\n",
    "\n",
    "sample2 = \"\"\"\n",
    "You are talking to Karen. She is a 29-year-old woman who has been a teacher for the past 12 years.\n",
    "She has two children, who are 12 and 15 years old.\n",
    "\"\"\"\n",
    "\n",
    "agent = Agent(\n",
    "    model=\"gpt-4o\",\n",
    "    model_type=\"chat\",\n",
    "    json_schema=User,\n",
    ")\n",
    "\n",
    "task = Task(\n",
    "    user=\"Extract the data from the text: \\n\\n {user}\",\n",
    "    agent=agent,\n",
    "    simple_response=True\n",
    ")\n",
    "\n",
    "workflow = Workflow(\n",
    "    [\n",
    "        [task, \"user_output\"],\n",
    "        [check_children, \"children_output\"],\n",
    "    ]\n",
    ")\n",
    "    \n",
    "response = workflow.run({\"user\": sample2})\n",
    "\n",
    "print()\n",
    "print(response[\"children_output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow: Conditional Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repenseai.genai.agent import Agent\n",
    "from repenseai.genai.tasks.api import Task\n",
    "from repenseai.genai.tasks.workflow import Workflow\n",
    "from repenseai.genai.tasks.conditional import BooleanConditionalTask\n",
    "from repenseai.genai.tasks.function import FunctionTask\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "def check_children(context: dict):\n",
    "    children = context[\"user_output\"][\"children\"]\n",
    "    return children > 0\n",
    "\n",
    "def return_exit(context: dict):\n",
    "    return \"Exit\"\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    children: int\n",
    "\n",
    "\n",
    "sample1 = \"\"\"\n",
    "My name is Samuel, I'm 36 years old and I dont have kids.\n",
    "\"\"\"\n",
    "\n",
    "sample2 = \"\"\"\n",
    "You are talking to Karen. She is a 29-year-old woman who has been a teacher for the past 12 years.\n",
    "She has two children, who are 12 and 15 years old.\n",
    "\"\"\"\n",
    "\n",
    "agent = Agent(\n",
    "    model=\"gpt-4o\",\n",
    "    model_type=\"chat\",\n",
    "    json_schema=User,\n",
    ")\n",
    "\n",
    "agent2 = Agent(\n",
    "    model=\"claude-3-7-sonnet-20250219\",\n",
    "    model_type=\"chat\",\n",
    ")\n",
    "\n",
    "task = Task(\n",
    "    user=\"Extract the data from the text: {user}\",\n",
    "    agent=agent,\n",
    "    simple_response=True\n",
    ")\n",
    "\n",
    "task2 = Task(\n",
    "    user=\"Create a sales pitch for {user_output} to travel to disneyland.\",\n",
    "    agent=agent2,\n",
    "    simple_response=True\n",
    ")\n",
    "\n",
    "bool_task = BooleanConditionalTask(\n",
    "    condition=check_children,\n",
    "    true_task=task2,\n",
    "    false_task=FunctionTask(return_exit),\n",
    ")\n",
    "\n",
    "workflow = Workflow(\n",
    "    [\n",
    "        [task, \"user_output\"],\n",
    "        [bool_task, \"sales_pitch\"],\n",
    "    ]\n",
    ")\n",
    "    \n",
    "response = workflow.run({\"user\": sample1}) # \"can you tell me a joke?\"\n",
    "\n",
    "print()\n",
    "print(response[\"sales_pitch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repenseai.genai.agent import Agent\n",
    "from repenseai.genai.tasks.api import Task\n",
    "\n",
    "def get_weather(latitude: float, longitude: float) -> str:\n",
    "    \"\"\"Get weather information for a location\"\"\"\n",
    "    return \"Sunny, 22°C\"\n",
    "\n",
    "def get_location(city: str) -> tuple:\n",
    "    \"\"\"Get coordinates for a city\"\"\"\n",
    "    return (48.8566, 2.3522)  # Example for Paris\n",
    "\n",
    "# Initialize agent with tools\n",
    "agent = Agent(\n",
    "    model=\"claude-3-7-sonnet-20250219\",\n",
    "    model_type=\"chat\",\n",
    "    tools=[get_weather, get_location]\n",
    ")\n",
    "\n",
    "# Create task\n",
    "task = Task(\n",
    "    user=\"can you tell me a joke?\", # \"can you tell me a joke?\", \"What's the weather like in Paris today?\"\n",
    "    agent=agent\n",
    ")\n",
    "\n",
    "response = task.run()\n",
    "\n",
    "print()\n",
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCP Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.anthropic.com/news/model-context-protocol\n",
    "# https://modelcontextprotocol.io/\n",
    "\n",
    "# https://github.com/modelcontextprotocol/python-sdk (fastmcp - client sample)\n",
    "# https://modelcontextprotocol.io/quickstart/client (chat loop code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta=None nextCursor=None prompts=[Prompt(name='check_bmi', description=\"Check the BMI based on user's name\", arguments=[PromptArgument(name='bmi', description=None, required=True), PromptArgument(name='user_name', description=None, required=True)])]\n",
      "Eu sou um atleta, considere isso e faça uma avaliação do meu BMI:\n",
      "\n",
      "33.23\n",
      "meta=None nextCursor=None tools=[Tool(name='calculate_bmi', description='Calculate BMI given weight in kg and height in meters', inputSchema={'properties': {'weight_kg': {'title': 'Weight Kg', 'type': 'number'}, 'height_m': {'title': 'Height M', 'type': 'number'}}, 'required': ['weight_kg', 'height_m'], 'title': 'calculate_bmiArguments', 'type': 'object'})]\n",
      "{\"weight_kg\": 95, \"height_m\": 1.77}\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Create server parameters for stdio connection\n",
    "server_params = StdioServerParameters(\n",
    "    command='python', \n",
    "    args=[\"servers/bmi.py\"],\n",
    ")\n",
    "\n",
    "async def run():\n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            # Initialize the connection\n",
    "            await session.initialize()\n",
    "\n",
    "            # List available prompts\n",
    "            prompts = await session.list_prompts()\n",
    "            print(prompts)\n",
    "\n",
    "            # Get a prompt\n",
    "            prompt = await session.get_prompt(\n",
    "                \"check_bmi\", arguments={\"bmi\": \"33.23\", \"user_name\": \"samuel\"}\n",
    "            )\n",
    "\n",
    "            print(prompt.messages[0].content.text)\n",
    "\n",
    "            # # List available resources\n",
    "            # resources = await session.list_resources()\n",
    "\n",
    "            # # List available tools\n",
    "            tools = await session.list_tools()\n",
    "            print(tools)\n",
    "\n",
    "            # # Read a resource\n",
    "            mime_type, content = await session.read_resource(\"file://profile/samuel\")\n",
    "            _, text = content\n",
    "            print(text[0].text)\n",
    "\n",
    "            # # Call a tool\n",
    "            # result = await session.call_tool(\"tool-name\", arguments={\"arg1\": \"value\"})\n",
    "\n",
    "asyncio.run(run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 17:08:22 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-04-09 17:08:27 - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-04-09 17:08:27 - ERROR - Error during server cleanup: Attempted to exit cancel scope in a different task than it was entered in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seu IMC é 30,3.\n",
      "\n",
      "Para contextualizar este resultado, aqui está a classificação do IMC segundo a OMS (Organização Mundial da Saúde):\n",
      "\n",
      "- Abaixo de 18,5: Abaixo do peso\n",
      "- 18,5 a 24,9: Peso normal\n",
      "- 25 a 29,9: Sobrepeso\n",
      "- 30 a 34,9: Obesidade grau I\n",
      "- 35 a 39,9: Obesidade grau II\n",
      "- Acima de 40: Obesidade grau III\n",
      "\n",
      "Com um IMC de 30,3, você está na faixa de Obesidade grau I. Seria recomendável consultar um profissional de saúde (médico e/ou nutricionista) para uma avaliação mais completa e orientações personalizadas, pois o IMC é apenas um dos vários indicadores de saúde.\n",
      "[{'role': 'user', 'content': [{'type': 'text', 'text': 'qual o meu bmi? altura: 1,77, peso: 95kg'}]}, {'role': 'assistant', 'content': [{'citations': None, 'text': 'Vou calcular seu BMI (Índice de Massa Corporal) usando sua altura de 1,77 metros e peso de 95 kg.', 'type': 'text'}, {'id': 'toolu_017wLVZbgEk8bPyYazARKnCF', 'input': {'height_m': 1.77, 'weight_kg': 95}, 'name': 'calculate_bmi', 'type': 'tool_use'}]}, {'role': 'user', 'content': [{'type': 'tool_result', 'tool_use_id': 'toolu_017wLVZbgEk8bPyYazARKnCF', 'content': \"[TextContent(type='text', text='30.323342589932647', annotations=None)]\"}]}, {'role': 'assistant', 'content': 'Seu IMC é 30,3.\\n\\nPara contextualizar este resultado, aqui está a classificação do IMC segundo a OMS (Organização Mundial da Saúde):\\n\\n- Abaixo de 18,5: Abaixo do peso\\n- 18,5 a 24,9: Peso normal\\n- 25 a 29,9: Sobrepeso\\n- 30 a 34,9: Obesidade grau I\\n- 35 a 39,9: Obesidade grau II\\n- Acima de 40: Obesidade grau III\\n\\nCom um IMC de 30,3, você está na faixa de Obesidade grau I. Seria recomendável consultar um profissional de saúde (médico e/ou nutricionista) para uma avaliação mais completa e orientações personalizadas, pois o IMC é apenas um dos vários indicadores de saúde.'}]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from repenseai.genai.mcp.server import Server\n",
    "from repenseai.genai.agent import AsyncAgent\n",
    "from repenseai.genai.tasks.api import AsyncTask\n",
    "\n",
    "server = Server(\n",
    "    name=\"teste_mcp\", \n",
    "    command='python', \n",
    "    args=[\"servers/bmi.py\"]\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    agent = AsyncAgent(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        model_type=\"chat\",\n",
    "        server=server\n",
    "    )\n",
    "\n",
    "    task = AsyncTask(\n",
    "        user=\"qual o meu bmi? altura: {altura}, peso: {peso}\",\n",
    "        agent=agent\n",
    "    )\n",
    "    \n",
    "    response = await task.run({\"altura\": \"1,77\", \"peso\": \"95kg\"})\n",
    "    print(\"\\n\"+response['response'])\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python codigos/fundamentos_ai/servers/memory.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://brains.dev/2024/embeddings-medidas-de-distancia-e-similaridade/\n",
    "\n",
    "# https://platform.openai.com/docs/guides/embeddings\n",
    "# https://cohere.com/pt/rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    dot_product = np.dot(embedding1, embedding2)\n",
    "\n",
    "    norm1 = np.linalg.norm(embedding1)\n",
    "    norm2 = np.linalg.norm(embedding2)\n",
    "\n",
    "    similarity = dot_product / (norm1 * norm2)\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "text1 = \"A filha do Samuel se chama Elisa\"\n",
    "text2 = \"Os gatos do Samuel se chamam pelanca (gordinha), katika (pequena) e blue (medrosa)\"\n",
    "\n",
    "database = [text1, text2]\n",
    "database_embeddings = client.embeddings.create(input=database, model=\"text-embedding-3-small\")\n",
    "\n",
    "query = \"Qual o nome da gata gordinha do Samuel?\"\n",
    "query_embedding = client.embeddings.create(input=query, model=\"text-embedding-3-small\").data[0].embedding\n",
    "\n",
    "similarities = [cosine_similarity(query_embedding, doc_embedding.embedding) for doc_embedding in database_embeddings.data]\n",
    "most_similar_index = np.argmax(similarities)\n",
    "\n",
    "database_text = database[most_similar_index]\n",
    "\n",
    "prompt = (\n",
    "    \"Você é um agente especializado em responder perguntas. \"\n",
    "    \"Use a base de dados fornecida para responder melhorar sua resposta\"\n",
    "    f\"Base de dados:\\n\\n{database_text}\\n\\n\"\n",
    "    f\"Pergunta:\\n\\n {query}\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ], \n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_embeddings.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
