{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.anthropic.com/engineering/building-effective-agents\n",
    "# https://www.agentrecipes.com/\n",
    "\n",
    "# https://www.arionkoder.com/blog/building-an-ai-powered-eligibility-system-for-us-healthcare-part-i\n",
    "# https://www.arionkoder.com/blog/building-an-ai-powered-eligibility-system-for-us-healthcare-part-ii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repenseai.genai.agent import Agent\n",
    "from repenseai.genai.tasks.api import Task\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    model=\"claude-3-7-sonnet-20250219\", # \"claude-3-5-sonnet-20241022\"\n",
    "    model_type=\"chat\",\n",
    ")\n",
    "\n",
    "task = Task(\n",
    "    user=\"What is the capital of france?\",\n",
    "    agent=agent,\n",
    "    simple_response=True\n",
    ")\n",
    "\n",
    "response = task.run()\n",
    "\n",
    "print()\n",
    "print(response.replace(\". \", \".\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python fundamentos_ai/characters.py 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Call - Output Estruturado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repenseai.genai.agent import Agent\n",
    "from repenseai.genai.tasks.api import Task\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    children: int\n",
    "\n",
    "\n",
    "sample1 = \"\"\"\n",
    "My name is Samuel, I'm 36 years old and I have a 3-month-old daughter and I want to have 3 more kids.\n",
    "\"\"\"\n",
    "\n",
    "sample2 = \"\"\"\n",
    "You are talking to Karen. She is a 30-year-old woman who has been a teacher for the past 12 years.\n",
    "She has two children, who are 12 and 15 years old.\n",
    "\"\"\"\n",
    "\n",
    "agent = Agent(\n",
    "    model=\"gpt-4o\",\n",
    "    model_type=\"chat\",\n",
    "    json_mode=True,\n",
    "    json_schema=User,\n",
    ")\n",
    "\n",
    "task = Task(\n",
    "    user=\"Extract the data from the text: \\n\\n {user}\",\n",
    "    agent=agent,\n",
    "    simple_response=True\n",
    ")\n",
    "\n",
    "response = task.run({\"user\": sample2})\n",
    "\n",
    "print()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repenseai.genai.agent import Agent\n",
    "from repenseai.genai.tasks.api import Task\n",
    "from repenseai.genai.tasks.workflow import Workflow\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "def check_children(context: dict):\n",
    "    children = context[\"user_output\"][\"children\"]\n",
    "    return children > 0\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    children: int\n",
    "\n",
    "\n",
    "sample1 = \"\"\"\n",
    "My name is Samuel, I'm 36 years and I dont have kids.\n",
    "\"\"\"\n",
    "\n",
    "sample2 = \"\"\"\n",
    "You are talking to Karen. She is a 29-year-old woman who has been a teacher for the past 12 years.\n",
    "She has two children, who are 12 and 15 years old.\n",
    "\"\"\"\n",
    "\n",
    "agent = Agent(\n",
    "    model=\"gpt-4o\",\n",
    "    model_type=\"chat\",\n",
    "    json_mode=True,\n",
    "    json_schema=User,\n",
    ")\n",
    "\n",
    "task = Task(\n",
    "    user=\"Extract the data from the text: \\n\\n {user}\",\n",
    "    agent=agent,\n",
    "    simple_response=True\n",
    ")\n",
    "\n",
    "workflow = Workflow(\n",
    "    [\n",
    "        [task, \"user_output\"],\n",
    "        [check_children, \"children_output\"],\n",
    "    ]\n",
    ")\n",
    "    \n",
    "response = workflow.run({\"user\": sample2})\n",
    "\n",
    "print()\n",
    "print(response[\"children_output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow: Conditional Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repenseai.genai.agent import Agent\n",
    "from repenseai.genai.tasks.api import Task\n",
    "from repenseai.genai.tasks.workflow import Workflow\n",
    "from repenseai.genai.tasks.conditional import BooleanConditionalTask\n",
    "from repenseai.genai.tasks.function import FunctionTask\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "def check_children(context: dict):\n",
    "    children = context[\"user_output\"][\"children\"]\n",
    "    return children > 0\n",
    "\n",
    "def return_exit(context: dict):\n",
    "    return \"Exit\"\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    children: int\n",
    "\n",
    "\n",
    "sample1 = \"\"\"\n",
    "My name is Samuel, I'm 36 years old and I dont have kids.\n",
    "\"\"\"\n",
    "\n",
    "sample2 = \"\"\"\n",
    "You are talking to Karen. She is a 29-year-old woman who has been a teacher for the past 12 years.\n",
    "She has two children, who are 12 and 15 years old.\n",
    "\"\"\"\n",
    "\n",
    "agent = Agent(\n",
    "    model=\"gpt-4o\",\n",
    "    model_type=\"chat\",\n",
    "    json_mode=True,\n",
    "    json_schema=User,\n",
    ")\n",
    "\n",
    "agent2 = Agent(\n",
    "    model=\"claude-3-7-sonnet-20250219\",\n",
    "    model_type=\"chat\",\n",
    ")\n",
    "\n",
    "task = Task(\n",
    "    user=\"Extract the data from the text: {user}\",\n",
    "    agent=agent,\n",
    "    simple_response=True\n",
    ")\n",
    "\n",
    "task2 = Task(\n",
    "    user=\"Create a sales pitch for {user_output} to travel to disneyland.\",\n",
    "    agent=agent2,\n",
    "    simple_response=True\n",
    ")\n",
    "\n",
    "bool_task = BooleanConditionalTask(\n",
    "    condition=check_children,\n",
    "    true_task=task2,\n",
    "    false_task=FunctionTask(return_exit),\n",
    ")\n",
    "\n",
    "workflow = Workflow(\n",
    "    [\n",
    "        [task, \"user_output\"],\n",
    "        [bool_task, \"sales_pitch\"],\n",
    "    ]\n",
    ")\n",
    "    \n",
    "response = workflow.run({\"user\": sample1}) # \"can you tell me a joke?\"\n",
    "\n",
    "print()\n",
    "print(response[\"sales_pitch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repenseai.genai.agent import Agent\n",
    "from repenseai.genai.tasks.api import Task\n",
    "\n",
    "def get_weather(latitude: float, longitude: float) -> str:\n",
    "    \"\"\"Get weather information for a location\"\"\"\n",
    "    return \"Sunny, 22°C\"\n",
    "\n",
    "def get_location(city: str) -> tuple:\n",
    "    \"\"\"Get coordinates for a city\"\"\"\n",
    "    return (48.8566, 2.3522)  # Example for Paris\n",
    "\n",
    "# Initialize agent with tools\n",
    "agent = Agent(\n",
    "    model=\"claude-3-7-sonnet-20250219\",\n",
    "    model_type=\"chat\",\n",
    "    tools=[get_weather, get_location]\n",
    ")\n",
    "\n",
    "# Create task\n",
    "task = Task(\n",
    "    user=\"can you tell me a joke?\", # \"can you tell me a joke?\", \"What's the weather like in Paris today?\"\n",
    "    agent=agent\n",
    ")\n",
    "\n",
    "response = task.run()\n",
    "\n",
    "print()\n",
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCP Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.anthropic.com/news/model-context-protocol\n",
    "# https://modelcontextprotocol.io/\n",
    "\n",
    "# https://github.com/modelcontextprotocol/python-sdk (fastmcp - client sample)\n",
    "# https://modelcontextprotocol.io/quickstart/client (chat loop code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from repenseai.genai.mcp.server import Server\n",
    "from repenseai.genai.agent import AsyncAgent\n",
    "from repenseai.genai.tasks.api import AsyncTask\n",
    "\n",
    "server = Server(\n",
    "    name=\"teste_mcp\", \n",
    "    command='python', \n",
    "    args=[\"servers/bmi.py\"]\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    agent = AsyncAgent(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        model_type=\"chat\",\n",
    "        server=server\n",
    "    )\n",
    "\n",
    "    task = AsyncTask(\n",
    "        user=\"qual o meu bmi? altura: {altura}, peso: {peso}\",\n",
    "        agent=agent\n",
    "    )\n",
    "    \n",
    "    response = await task.run({\"altura\": \"1,77\", \"peso\": \"95kg\"})\n",
    "    print(\"\\n\"+response['response'])\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python fundamentos_ai/servers/memory.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://brains.dev/2024/embeddings-medidas-de-distancia-e-similaridade/\n",
    "\n",
    "# https://platform.openai.com/docs/guides/embeddings\n",
    "# https://cohere.com/pt/rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    dot_product = np.dot(embedding1, embedding2)\n",
    "\n",
    "    norm1 = np.linalg.norm(embedding1)\n",
    "    norm2 = np.linalg.norm(embedding2)\n",
    "\n",
    "    similarity = dot_product / (norm1 * norm2)\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "text1 = \"A filha do Samuel se chama Elisa\"\n",
    "text2 = \"Os gatos do Samuel se chamam pelanca (gordinha), katika (pequena) e blue (medrosa)\"\n",
    "\n",
    "database = [text1, text2]\n",
    "database_embeddings = client.embeddings.create(input=database, model=\"text-embedding-3-small\")\n",
    "\n",
    "query = \"Qual o nome da gata gordinha do Samuel?\"\n",
    "query_embedding = client.embeddings.create(input=query, model=\"text-embedding-3-small\").data[0].embedding\n",
    "\n",
    "similarities = [cosine_similarity(query_embedding, doc_embedding.embedding) for doc_embedding in database_embeddings.data]\n",
    "most_similar_index = np.argmax(similarities)\n",
    "\n",
    "database_text = database[most_similar_index]\n",
    "\n",
    "prompt = (\n",
    "    \"Você é um agente especializado em responder perguntas. \"\n",
    "    \"Use a base de dados fornecida para responder melhorar sua resposta\"\n",
    "    f\"Base de dados:\\n\\n{database_text}\\n\\n\"\n",
    "    f\"Pergunta:\\n\\n {query}\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ], \n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_embeddings.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
